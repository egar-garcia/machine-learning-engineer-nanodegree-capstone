{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pyramid/__init__.py:68: UserWarning: \n",
      "    The 'pyramid' package will be migrating to a new namespace beginning in \n",
      "    version 1.0.0: 'pmdarima'. This is due to a package name collision with the\n",
      "    Pyramid web framework. For more information, see Issue #34:\n",
      "    \n",
      "        https://github.com/tgsmith61591/pyramid/issues/34\n",
      "        \n",
      "    The package will subsequently be installable via the name 'pmdarima'; the\n",
      "    only functional change to the user will be the import name. All imports\n",
      "    from 'pyramid' will change to 'pmdarima'.\n",
      "    \n",
      "  \"\"\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions to support the constructions in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_in_dataframe(df):\n",
    "    \"\"\"\n",
    "    It breaks the date attibute (assuming it's a datetime) of a dataframe in more fileds\n",
    "    for year, month, day, week, day of week, day of year and timestamp.\n",
    "    \"\"\"\n",
    "    df['year'] = df.date.dt.year\n",
    "    df['month'] = df.date.dt.month\n",
    "    df['day'] = df.date.dt.day\n",
    "    df['week'] = df.date.dt.week\n",
    "    df['dayofweek'] = df.date.dt.dayofweek\n",
    "    df['dayofyear'] = df.date.dt.dayofyear\n",
    "    df['timestamp'] = df.date.values.astype(np.int64)\n",
    "\n",
    "\n",
    "def str_to_datetime(date):\n",
    "    \"\"\"\n",
    "    Converts a string into a datetime.\n",
    "\n",
    "    :param str date: The string representation in the format 'yyyy-mm-dd' of the date to convert.\n",
    "    :return: The resulting datetime.\n",
    "    :rtype: datetime.datetime\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "def datetime_array_to_dataframe(days):\n",
    "    \"\"\"\n",
    "    Gets a dataframe from an array of dates.\n",
    "\n",
    "    :param list[datetime.datetime] date: The array of dates.\n",
    "    :return: The dataframe.\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({'date': days})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    This class is used to manage the dataset that contains the hsitoric stock prices\n",
    "    for the companies contemplated in the Dow Jones Industrial Average.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Ticker symbols of the companies contemplated in the  Dow Jones Industrial Average. \"\"\"\n",
    "    DJIA_TICKERS = [\n",
    "        'BA',   'PFE', 'MCD', 'WMT', 'KO',   'MRK',  'HD',   'V',   'JNJ',  'VZ',\n",
    "        'CSCO', 'AXP', 'TRV', 'DIS', 'MSFT', 'UNH',  'DWDP', 'CAT', 'AAPL', 'UTX',\n",
    "        'MMM',  'JPM', 'IBM', 'GS',  'XOM',  'INTC', 'NKE',  'CVX', 'PG',   'WBA' ]\n",
    "\n",
    "    \"\"\" Value used to get the historical data from 5 years ago. \"\"\"\n",
    "    HIST_5Y = '5y'\n",
    "\n",
    "    \"\"\" Value used to get the historical data from 1 year ago. \"\"\"\n",
    "    HIST_1Y = '1y'\n",
    "\n",
    "    \"\"\" Value used to get the historical data from 1 month ago. \"\"\"\n",
    "    HIST_1M = '1m'\n",
    "\n",
    "    \"\"\"\n",
    "    This is the template to create the URL to extract historical stock prices\n",
    "    from the IEX API.\n",
    "    \"\"\"\n",
    "    __IEX_API_URL_TEMPLATE = 'https://api.iextrading.com/1.0/stock/{}/chart/{}'\n",
    "\n",
    "\n",
    "    def __init__(self, dataframe=None):\n",
    "        \"\"\"\n",
    "        The constructor of Dataset.\n",
    "\n",
    "        :param pandas.DataFrame df: The dataframe containing stock price historical records,\n",
    "                                    which will be actual data.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __preprocess_dataframe(df):\n",
    "        \"\"\"\n",
    "        Pre-processes a dataframe containing stock price historical records (from IEX)\n",
    "        by removing the columns that are not useful to make future predictions\n",
    "        and expanding the date in more columns.\n",
    "\n",
    "        :param pandas.DataFrame df: The dataframe containing stock price historical records.\n",
    "        :return: The pre-processed dataframe.\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        formated_df = df.drop(['label',\n",
    "                               'change', 'changeOverTime', 'changePercent',\n",
    "                               'high', 'low', 'open',\n",
    "                               'unadjustedVolume', 'volume', 'vwap'],\n",
    "                              axis=1)\n",
    "\n",
    "        expand_date_in_dataframe(formated_df)\n",
    "        return formated_df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_dataframe_for_ticker(ticker_symbol, hist_period):\n",
    "        \"\"\"\n",
    "        Retrieves the historic prices for a particuler stock from the data source,\n",
    "        i.e. the IEX API.\n",
    "\n",
    "        :param str ticker_symbol: The ticker symbol or symbols to filter the data.\n",
    "        :param str hist_period: The period to retrieve historical records,\n",
    "                                p.e '5y' for 5 years, '1y' for 1 year, '1m' for 1 month, etc.\n",
    "        :return: The dataframe containing the historic prices.\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        # Getting the historic records from IEX\n",
    "        r = requests.get(url=Dataset.__IEX_API_URL_TEMPLATE.format(ticker_symbol.lower(), hist_period))\n",
    "        df = json_normalize(r.json())\n",
    "\n",
    "        # Converting the date to a datetime\n",
    "        df.date = pd.to_datetime(df.date, format='%Y-%m-%d')\n",
    "\n",
    "        # Adding the ticker symbol as a new column\n",
    "        df.insert(loc=0, column='symbol', value=ticker_symbol)\n",
    "\n",
    "        return Dataset.__preprocess_dataframe(df)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_djia_dataframe(hist_period):\n",
    "        \"\"\"\n",
    "        Gets a dataframe containing historic prices for stocks in the Dow Jones Industrial Average.\n",
    "\n",
    "        :param str hist_period: The period to retrieve historical records,\n",
    "                                p.e '5y' for 5 years, '1y' for 1 year, '1m' for 1 month, etc.\n",
    "        :return: The dataframe containing the historic prices.\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        df = None\n",
    "\n",
    "        # Retrieves the historic records for each one of the ticker symbols in the\n",
    "        # Dow Jones Industrial Average\n",
    "        for ticker_symbol in Dataset.DJIA_TICKERS:\n",
    "            if df is None:\n",
    "                df = Dataset.__get_dataframe_for_ticker(ticker_symbol, hist_period)\n",
    "            else:\n",
    "                df = df.append(Dataset.__get_dataframe_for_ticker(ticker_symbol, hist_period))\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __update_djia_dataframe(df):\n",
    "        \"\"\"\n",
    "        Updates a dataframe containing historic prices for stocks in the Dow Jones Industrial Average,\n",
    "        by retrieving the most recent records from the information source.\n",
    "\n",
    "        :param pandas.DataFrame hist_period: The dataframe containing stock price historical records.\n",
    "        :return: The dataframe containing the historic prices.\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting the amount of days that need to be updated\n",
    "        last_recorded_day = max(df.date)\n",
    "        today = datetime.datetime.now()\n",
    "        days_to_update = (today - last_recorded_day).days\n",
    "\n",
    "        # Deciding the historic period to request to the source according to the days that\n",
    "        # need to be updated\n",
    "        hist_period = Dataset.HIST_5Y\n",
    "        if days_to_update < 1:\n",
    "            return df\n",
    "        elif days_to_update < 28:\n",
    "            hist_period = Dataset.HIST_1M\n",
    "        elif days_to_update < 365:\n",
    "            hist_period = Dataset.HIST_1Y\n",
    "\n",
    "        # Getting the data frame containing the missing records\n",
    "        last_df = Dataset.__get_djia_dataframe(hist_period)\n",
    "\n",
    "        # Appending the missing records, dropping the duplicates and returning\n",
    "        return df.append(last_df).drop_duplicates(['symbol', 'date'], keep='last')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def loadDatasetFromFile(file_name):\n",
    "        \"\"\"\n",
    "        Loads the dataset from a file where data was previously stored.\n",
    "\n",
    "        :param str file_name: The name of the file to load the data from. \n",
    "        \"\"\"\n",
    "        with open(file_name, 'rb') as fp:\n",
    "            return Dataset(pickle.load(fp))\n",
    "\n",
    "\n",
    "    def saveDataToFile(self, file_name=None):\n",
    "        \"\"\"\n",
    "        Saves the current dataset to a file.\n",
    "\n",
    "        :param file_name: The name of the file to save the data,\n",
    "                          if None the data is saved to a file n the 'data' directory\n",
    "                          using a name of the form 'djia_yyyymmdd-yyyymmdd.pkl'\n",
    "                          with the minimum and maximum recorded dates. \n",
    "        :type file_name: str or None\n",
    "        \"\"\"\n",
    "        if file_name is None:\n",
    "            file_name = os.path.join(\n",
    "                'data',\n",
    "                'djia_{:%Y%m%d}-{:%Y%m%d}.pkl'.format(min(self.dataframe.date), max(self.dataframe.date)))\n",
    "\n",
    "        with open(file_name, 'wb') as fp:\n",
    "            pickle.dump(self.dataframe, fp)\n",
    "\n",
    "\n",
    "    def createData(self, hist_period=HIST_5Y):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with brand new data,\n",
    "        by default it retrieves historical records from the last 5 years.\n",
    "\n",
    "        :param str hist_period: The period to retrieve historical records, 5 years ('5y') by default.\n",
    "        \"\"\"\n",
    "        self.dataframe = Dataset.__get_djia_dataframe(hist_period)\n",
    "\n",
    "\n",
    "    def updateData(self):\n",
    "        \"\"\"\n",
    "        Updates the dataset by getting the most recent history records from the source.\n",
    "        Note: This method is intended to be run periodicaly in order to keep the dataset up to date.\n",
    "        \"\"\"\n",
    "        self.dataframe = Dataset.__update_djia_dataframe(self.dataframe)\n",
    "\n",
    "\n",
    "    def getDataframe(self, ticker_symbol=None, from_date=None, to_date=None):\n",
    "        \"\"\"\n",
    "        Gets a dataframe containing a subset of the records of the current dataset,\n",
    "        which is obtained by filtering by a ticker symbol or list (array) of ticker symbols\n",
    "        and/or a date range.\n",
    "\n",
    "        :param ticker_symbol: The ticker symbol or symbols to filter the data.\n",
    "        :type ticker_symbol: str or list[str] or None\n",
    "        :param from_date: The minimum date to appear in the records of the subset.\n",
    "        :type from_date: datetime.datetime or None\n",
    "        :param to_date: The maximum date to appear in the records of the subset.\n",
    "        :type to_date: datetime.datetime or None\n",
    "        :return: The dataframe with the subset resulted of filtering the dataset.\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        df = self.dataframe\n",
    "\n",
    "        if ticker_symbol is not None:\n",
    "            if isinstance(ticker_symbol, str): # If ticker_symbol symbol is a string\n",
    "                df = df.query(\"symbol == '{}'\".format(ticker_symbol))\n",
    "            elif isinstance(ticker_symbol, list): # If ticker_symbol symbol is an array\n",
    "                # Creates a query expression as a sequence of ORs\n",
    "                ticker_symbol_query = None\n",
    "                for t in ticker_symbol:\n",
    "                    ticker_symbol_exp = \"symbol == '{}'\".format(t)\n",
    "                    if ticker_symbol_query is None:\n",
    "                        ticker_symbol_query = ticker_symbol_exp\n",
    "                    else:\n",
    "                        ticker_symbol_query += \"or \" + ticker_symbol_exp\n",
    "                df = df.query(ticker_symbol_query)\n",
    "\n",
    "        if from_date is not None:\n",
    "            df = df.query(\"date >= '{}'\".format(from_date))\n",
    "\n",
    "        if to_date is not None:\n",
    "            df = df.query(\"date <= '{}'\".format(to_date))\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    \n",
    "    def getSubset(self, ticker_symbol=None, from_date=None, to_date=None):\n",
    "        \"\"\"\n",
    "        Gets a subset of the current dataset filtered \n",
    "        by a ticker symbol or list (array) of ticker symbols and/or a date range.\n",
    "\n",
    "        :param ticker_symbol: The ticker symbol or symbols to filter the data.\n",
    "        :type ticker_symbol: str or list[str] or None\n",
    "        :param from_date: The minimum date to appear in the records of the subset.\n",
    "        :type from_date: datetime.datetime or None\n",
    "        :param to_date: The maximum date to appear in the records of the subset.\n",
    "        :type to_date: datetime.datetime or None\n",
    "        :return: The subset resulted of filtering the dataset.\n",
    "        :rtype: Dataset\n",
    "        \"\"\"\n",
    "        df = self.getDataframe(ticker_symbol=ticker_symbol, from_date=from_date, to_date=to_date)\n",
    "        return Dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingDaysHelper:\n",
    "\n",
    "    def __init__(self, market_holidays_file='market_holidays.txt'):\n",
    "        self.market_holidays = []\n",
    "\n",
    "        with open(market_holidays_file) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            self.market_holidays.append(datetime.datetime.strptime(line.strip(), '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "    def __is_trading_day(self, day):\n",
    "        day_of_week = day.weekday()\n",
    "        if day_of_week == 5 or day_of_week == 6 or day in self.market_holidays:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    def get_trading_days_in_range(self, start_date, end_date):\n",
    "        trading_days = []\n",
    "\n",
    "        current_day = start_date\n",
    "        while (current_day <= end_date):\n",
    "            if self.__is_trading_day(current_day):\n",
    "                trading_days.append(current_day)\n",
    "            current_day += datetime.timedelta(days=1)\n",
    "\n",
    "        return trading_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockForecasterModel:\n",
    "    def __init__(self, ticker_symbol, dataset, trading_days_helper):\n",
    "        self.ticker_symbol = ticker_symbol\n",
    "        self.dataset = dataset\n",
    "        self.trading_days_helper = trading_days_helper\n",
    "\n",
    "    def train(self, start_date, end_date):\n",
    "        raise NotImplementedError('Please Implement this method')\n",
    "\n",
    "    def predict(self, from_date, to_date):\n",
    "        raise NotImplementedError('Please Implement this method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStockForecaster(StockForecasterModel):\n",
    "\n",
    "    def __init__(self, ticker_symbol, dataset, trading_days_helper):\n",
    "        StockForecasterModel.__init__(self, ticker_symbol, dataset, trading_days_helper)\n",
    "\n",
    "    def train(self, start_date=None, end_date=None):\n",
    "        training_set = self.dataset.getDataframe(ticker_symbol=self.ticker_symbol,\n",
    "                                                 from_date=start_date, to_date=end_date)\n",
    "\n",
    "        x = training_set.drop(['symbol', 'date', 'close'], axis=1)\n",
    "        y = training_set.close\n",
    "\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(x, y)\n",
    "\n",
    "    def predict(self, from_date, to_date):\n",
    "        days_to_predict = self.trading_days_helper.get_trading_days_in_range(from_date, to_date)\n",
    "\n",
    "        x = datetime_array_to_dataframe(days_to_predict)\n",
    "        expand_date_in_dataframe(x)\n",
    "        x = x.drop(['date'], axis=1)\n",
    "\n",
    "        y = self.model.predict(x)\n",
    "        \n",
    "        return pd.DataFrame({'symbol': self.ticker_symbol, 'date': days_to_predict, 'predicted_price': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArimaStockForecaster(StockForecasterModel):\n",
    "\n",
    "    def __init__(self, ticker_symbol, dataset, trading_days_helper):\n",
    "        StockForecasterModel.__init__(self, ticker_symbol, dataset, trading_days_helper)\n",
    "        self.training_end = None\n",
    "\n",
    "    def train(self, start_date=None, end_date=None):\n",
    "        training_set = self.dataset.getDataframe(ticker_symbol=self.ticker_symbol,\n",
    "                                                 from_date=start_date, to_date=end_date)\n",
    "        self.training_end = max(training_set.date)\n",
    "\n",
    "        training_set = training_set.close\n",
    "\n",
    "        self.model = auto_arima(training_set,\n",
    "                                start_p=1, start_q=1, max_p=3, max_q=3, m=12, start_P=0,\n",
    "                                seasonal=True, d=1, D=1, trace=True,\n",
    "                                error_action='ignore', suppress_warnings=True)\n",
    "        self.model.fit(training_set)\n",
    "\n",
    "    def predict(self, from_date, to_date):\n",
    "        if from_date > to_date:\n",
    "            raise ValueError('Invalid date range to predict')\n",
    "        if from_date <= self.training_end:\n",
    "            raise ValueError('Date range to predict should be after last date used for training')\n",
    "\n",
    "        prediction_start = self.training_end + datetime.timedelta(days=1) \n",
    "        days_to_predict = self.trading_days_helper.get_trading_days_in_range(prediction_start, to_date)\n",
    "\n",
    "        y = self.model.predict(n_periods=days_to_predict.shape[0])\n",
    "        \n",
    "        return pd.DataFrame({'symbol': self.ticker_symbol, 'date': days_to_predict, 'predicted_price': y})\\\n",
    "                 .query(\"date >= '{}' and date <= {}\".format(from_date, to_date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(results, subplot, model_constructor, total_dataset,\n",
    "                        ticker_symbol,\n",
    "                        training_start, training_end,\n",
    "                        validation_days=[1, 7, 15, 30, 60, 90, 180],\n",
    "                        simulate_up_to_date_dataset=False):\n",
    "\n",
    "    validation_start = training_end + datetime.timedelta(days=1)\n",
    "    max_validation_end = validation_start + datetime.timedelta(days=max(validation_days))\n",
    "    total_validation_ds = total_dataset.getSubset(ticker_symbol=ticker_symbol,\n",
    "                                                  from_date=validation_start,\n",
    "                                                  to_date=max_validation_end)\n",
    "\n",
    "    training_df = total_dataset.getDataframe(ticker_symbol=ticker_symbol,\n",
    "                                             from_date=training_start,\n",
    "                                             to_date=training_end)\n",
    "\n",
    "    if simulate_up_to_date_dataset:\n",
    "        dataset = total_dataset.getSubset(ticker_symbol=ticker_symbol,\n",
    "                                          from_date=training_start,\n",
    "                                          to_date=max_validation_end)\n",
    "    else:\n",
    "        dataset = total_dataset.getSubset(ticker_symbol=ticker_symbol,\n",
    "                                          from_date=training_start,\n",
    "                                          to_date=training_end)\n",
    "\n",
    "    model = model_constructor(ticker_symbol, dataset, trading_days_helper)\n",
    "    model.train(start_date=training_start, end_date=training_end)\n",
    "\n",
    "    for v in validation_days:\n",
    "        validation_end = validation_start + datetime.timedelta(days=v)\n",
    "        preds = model.predict(validation_start, validation_end)\n",
    "        validation_df = total_validation_ds.getDataframe(ticker_symbol=ticker_symbol,\n",
    "                                                         from_date=validation_start,\n",
    "                                                         to_date=validation_end)\n",
    "\n",
    "        results.append({'symbol': ticker_symbol,\n",
    "                        'forecasting_days': v,\n",
    "                        'RMSE': rmse(preds.predicted_price.values, validation_df.close.values)})\n",
    "\n",
    "    subplot.plot(training_df.date, training_df.close, label='Training')\n",
    "    subplot.plot(total_validation_ds.dataframe.date, total_validation_ds.dataframe.close, label='Validation')\n",
    "    subplot.plot(preds.date, preds.predicted_price, label='Prediction')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=3009.708, BIC=3032.755, Fit time=6.364 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=3490.967, BIC=3500.185, Fit time=0.078 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=3266.890, BIC=3285.327, Fit time=1.160 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=3009.235, BIC=3027.673, Fit time=2.970 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=3009.268, BIC=3032.315, Fit time=3.001 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=3491.439, BIC=3505.267, Fit time=0.296 seconds\n",
      "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 2, 12); AIC=3009.178, BIC=3032.224, Fit time=9.815 seconds\n",
      "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 2, 12); AIC=3009.993, BIC=3037.649, Fit time=24.430 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 2, 12); AIC=3007.523, BIC=3025.961, Fit time=5.966 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 2, 12); AIC=3008.796, BIC=3031.842, Fit time=16.411 seconds\n",
      "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=3007.605, BIC=3021.433, Fit time=1.699 seconds\n",
      "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 2, 12); AIC=3009.217, BIC=3032.264, Fit time=10.444 seconds\n",
      "Total fit time: 82.639 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "n_periods must be an int or a long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4b3dd1b2bfae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#measure_performance(results, ax1, LinearStockForecaster, ds, 'AAPL', training_start, training_end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmeasure_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArimaStockForecaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-fdb7d4bb24eb>\u001b[0m in \u001b[0;36mmeasure_performance\u001b[0;34m(results, subplot, model_constructor, total_dataset, ticker_symbol, training_start, training_end, validation_days, simulate_up_to_date_dataset)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_days\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mvalidation_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         validation_df = total_validation_ds.getDataframe(ticker_symbol=ticker_symbol,\n\u001b[1;32m     33\u001b[0m                                                          \u001b[0mfrom_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-3a0c04df9c70>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, from_date, to_date)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdays_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrading_days_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trading_days_in_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdays_to_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker_symbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdays_to_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted_price'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pyramid/arima/arima.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n_periods, exogenous, return_conf_int, alpha)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arima_res_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_periods must be an int or a long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# if we fit with exog, make sure one was passed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: n_periods must be an int or a long"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBkAAAFpCAYAAADZZfCUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE9lJREFUeJzt3X+I5fdd7/HXu1ljodYW3L0g2Y0JuL117RXaO+RW+oeF9l42+WP3D72ShaKV0P3HiNoiRJQq8a8qV0GIP1Ys1YKNsX/IgCu5oJGCmJIpvTc0KZEhepuNhWxrbv4pbcz17R9zvIzj7szp5j0zZzqPByyc7/d8zjnvfz7M7nO/5zvV3QEAAAB4vd5w2AMAAAAA3xpEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEbsGRmq6uNV9VJVfeEmz1dV/WZVbVbV01X1rvkxAQAAgFW3zJUMn0hyfpfn701ydvHncpLffv1jAQAAAEfNnpGhuz+T5B93WXIxyR/2lieTvLWqvntqQAAAAOBomLgnwx1JXth2fG1xDgAAADhGThzkh1XV5Wx9pSJvetOb/vPb3/72g/x4AAAAYA+f+9znvtLdp27ltROR4cUkZ7Ydn16c+3e6+0qSK0mytrbWGxsbAx8PAAAATKmq/3Orr534usR6kh9b/JaJdyd5pbu/PPC+AAAAwBGy55UMVfWpJO9NcrKqriX5pSTfliTd/TtJria5L8lmkq8l+Yn9GhYAAABYXXtGhu6+tMfzneQnxyYCAAAAjqSJr0sAAAAAiAwAAADADJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMGKpyFBV56vquararKqHbvD8nVX1RFV9vqqerqr75kcFAAAAVtmekaGqbkvySJJ7k5xLcqmqzu1Y9otJHuvudya5P8lvTQ8KAAAArLZlrmS4J8lmdz/f3a8meTTJxR1rOsl3Lh6/Jck/zI0IAAAAHAUnllhzR5IXth1fS/Jfdqz55ST/s6p+Ksmbkrx/ZDoAAADgyJi68eOlJJ/o7tNJ7kvyyar6d+9dVZeraqOqNq5fvz700QAAAMAqWCYyvJjkzLbj04tz2z2Q5LEk6e6/SfLGJCd3vlF3X+nute5eO3Xq1K1NDAAAAKykZSLDU0nOVtXdVXV7tm7suL5jzZeSvC9Jqur7shUZXKoAAAAAx8iekaG7X0vyYJLHk3wxW79F4pmqeriqLiyWfSTJh6rqfyf5VJIPdnfv19AAAADA6lnmxo/p7qtJru4499Ftj59N8p7Z0QAAAICjZOrGjwAAAMAxJzIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABixVGSoqvNV9VxVbVbVQzdZ86NV9WxVPVNVfzQ7JgAAALDqTuy1oKpuS/JIkv+a5FqSp6pqvbuf3bbmbJKfT/Ke7n65qv7Dfg0MAAAArKZlrmS4J8lmdz/f3a8meTTJxR1rPpTkke5+OUm6+6XZMQEAAIBVt0xkuCPJC9uOry3Obfe2JG+rqr+uqier6vyN3qiqLlfVRlVtXL9+/dYmBgAAAFbS1I0fTyQ5m+S9SS4l+b2qeuvORd19pbvXunvt1KlTQx8NAAAArIJlIsOLSc5sOz69OLfdtSTr3f1P3f13Sf42W9EBAAAAOCaWiQxPJTlbVXdX1e1J7k+yvmPNn2brKoZU1clsfX3i+cE5AQAAgBW3Z2To7teSPJjk8SRfTPJYdz9TVQ9X1YXFsseTfLWqnk3yRJKf6+6v7tfQAAAAwOqp7j6UD15bW+uNjY1D+WwAAADgxqrqc929diuvnbrxIwAAAHDMiQwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMGKpyFBV56vquararKqHdln3w1XVVbU2NyIAAABwFOwZGarqtiSPJLk3ybkkl6rq3A3WvTnJTyf57PSQAAAAwOpb5kqGe5Jsdvfz3f1qkkeTXLzBul9J8rEkXx+cDwAAADgilokMdyR5YdvxtcW5/6+q3pXkTHf/2W5vVFWXq2qjqjauX7/+TQ8LAAAArK7XfePHqnpDkl9P8pG91nb3le5e6+61U6dOvd6PBgAAAFbIMpHhxSRnth2fXpz7V29O8o4kf1VVf5/k3UnW3fwRAAAAjpdlIsNTSc5W1d1VdXuS+5Os/+uT3f1Kd5/s7ru6+64kTya50N0b+zIxAAAAsJL2jAzd/VqSB5M8nuSLSR7r7meq6uGqurDfAwIAAABHw4llFnX31SRXd5z76E3Wvvf1jwUAAAAcNa/7xo8AAAAAicgAAAAADBEZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACOWigxVdb6qnquqzap66AbPf7iqnq2qp6vqL6rqe+ZHBQAAAFbZnpGhqm5L8kiSe5OcS3Kpqs7tWPb5JGvd/QNJPp3kV6cHBQAAAFbbMlcy3JNks7uf7+5Xkzya5OL2Bd39RHd/bXH4ZJLTs2MCAAAAq26ZyHBHkhe2HV9bnLuZB5L8+esZCgAAADh6Tky+WVV9IMlakh+6yfOXk1xOkjvvvHPyowEAAIBDtsyVDC8mObPt+PTi3L9RVe9P8gtJLnT3N270Rt19pbvXunvt1KlTtzIvAAAAsKKWiQxPJTlbVXdX1e1J7k+yvn1BVb0zye9mKzC8ND8mAAAAsOr2jAzd/VqSB5M8nuSLSR7r7meq6uGqurBY9mtJviPJn1TV/6qq9Zu8HQAAAPAtaql7MnT31SRXd5z76LbH7x+eCwAAADhilvm6BAAAAMCeRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGCEyAAAAACNEBgAAAGCEyAAAAACMEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYITIAAAAAIwQGQAAAIARIgMAAAAwQmQAAAAARogMAAAAwAiRAQAAABghMgAAAAAjRAYAAABghMgAAAAAjBAZAAAAgBEiAwAAADBCZAAAAABGiAwAAADACJEBAAAAGLFUZKiq81X1XFVtVtVDN3j+26vqjxfPf7aq7poeFAAAAFhte0aGqrotySNJ7k1yLsmlqjq3Y9kDSV7u7u9N8htJPjY9KAAAALDalrmS4Z4km939fHe/muTRJBd3rLmY5A8Wjz+d5H1VVXNjAgAAAKtumchwR5IXth1fW5y74Zrufi3JK0m+a2JAAAAA4Gg4cZAfVlWXk1xeHH6jqr5wkJ8PR8zJJF857CFghdkjsDt7BHZnj8DN/cdbfeEykeHFJGe2HZ9enLvRmmtVdSLJW5J8decbdfeVJFeSpKo2unvtVoaG48Aegd3ZI7A7ewR2Z4/AzVXVxq2+dpmvSzyV5GxV3V1Vtye5P8n6jjXrSX588fhHkvxld/etDgUAAAAcPXteydDdr1XVg0keT3Jbko939zNV9XCSje5eT/L7ST5ZVZtJ/jFbIQIAAAA4Rpa6J0N3X01ydce5j257/PUk//2b/Owr3+R6OG7sEdidPQK7s0dgd/YI3Nwt74/yrQYAAABgwjL3ZAAAAADY075Hhqo6X1XPVdVmVT10g+e/var+ePH8Z6vqrv2eCVbJEnvkw1X1bFU9XVV/UVXfcxhzwmHZa49sW/fDVdVV5U7hHBvL7I+q+tHFz5FnquqPDnpGOExL/D3rzqp6oqo+v/i71n2HMScclqr6eFW9VFVfuMnzVVW/udhDT1fVu/Z6z32NDFV1W5JHktyb5FySS1V1bseyB5K83N3fm+Q3knxsP2eCVbLkHvl8krXu/oEkn07yqwc7JRyeJfdIqurNSX46yWcPdkI4PMvsj6o6m+Tnk7ynu78/yc8c+KBwSJb8GfKLSR7r7ndm6+b1v3WwU8Kh+0SS87s8f2+Ss4s/l5P89l5vuN9XMtyTZLO7n+/uV5M8muTijjUXk/zB4vGnk7yvqmqf54JVsece6e4nuvtri8Mnk5w+4BnhMC3zcyRJfiVbkfrrBzkcHLJl9seHkjzS3S8nSXe/dMAzwmFaZo90ku9cPH5Lkn84wPng0HX3Z7L1GyJv5mKSP+wtTyZ5a1V9927vud+R4Y4kL2w7vrY4d8M13f1akleSfNc+zwWrYpk9st0DSf58XyeC1bLnHllctnemu//sIAeDFbDMz5C3JXlbVf11VT1ZVbv9bxV8q1lmj/xykg9U1bVs/Ta9nzqY0eDI+Gb/vbLcr7AEDl9VfSDJWpIfOuxZYFVU1RuS/HqSDx7yKLCqTmTrEtf3ZutKuM9U1X/q7v97qFPB6riU5BPd/T+q6geTfLKq3tHd/3zYg8FRtd9XMryY5My249OLczdcU1UnsnWZ0lf3eS5YFcvskVTV+5P8QpIL3f2NA5oNVsFee+TNSd6R5K+q6u+TvDvJups/ckws8zPkWpL17v6n7v67JH+bregAx8Eye+SBJI8lSXf/TZI3Jjl5INPB0bDUv1e22+/I8FSSs1V1d1Xdnq2bqazvWLOe5McXj38kyV92d+/zXLAq9twjVfXOJL+brcDgu7QcN7vuke5+pbtPdvdd3X1Xtu5bcqG7Nw5nXDhQy/w960+zdRVDqupktr4+8fxBDgmHaJk98qUk70uSqvq+bEWG6wc6Jay29SQ/tvgtE+9O8kp3f3m3F+zr1yW6+7WqejDJ40luS/Lx7n6mqh5OstHd60l+P1uXJW1m64YT9+/nTLBKltwjv5bkO5L8yeKeqF/q7guHNjQcoCX3CBxLS+6Px5P8t6p6Nsn/S/Jz3e2KUY6FJffIR5L8XlX9bLZuAvlB/+HJcVJVn8pWjD65uDfJLyX5tiTp7t/J1r1K7kuymeRrSX5iz/e0hwAAAIAJ+/11CQAAAOCYEBkAAACAESIDAAAAMEJkAAAAAEaIDAAAAMAIkQEAAAAYITIAAAAAI0QGAAAAYMS/AMyFrDc74bd9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trading_days_helper = TradingDaysHelper()\n",
    "ds = Dataset.loadDatasetFromFile(os.path.join('data', 'djia_20140303-20190315.pkl'))\n",
    "\n",
    "training_start = str_to_datetime('2015-04-01')\n",
    "training_end = str_to_datetime('2018-03-31')\n",
    "\n",
    "results = []\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "#measure_performance(results, ax1, LinearStockForecaster, ds, 'AAPL', training_start, training_end)\n",
    "measure_performance(results, ax1, ArimaStockForecaster, ds, 'AAPL', training_start, training_end)\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['symbol', 'forecasting_days', 'RMSE'], data = results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "ds.loaDataFromFile('data/djia_20140303-20190315.pkl')\n",
    "df = ds.getDataframe(ticker_symbol='AAPL', from_date=str_to_datetime('2015-04-01'), to_date=str_to_datetime('2018-03-31'))\n",
    "plt.plot(df.date, df.close, label='Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "ds.loaDataFromFile('data/djia_20140303-20190315.pkl')\n",
    "#ds.createData(hist_period=Dataset.HIST_1Y)\n",
    "#ds.createData()\n",
    "\n",
    "df = ds.getDataframe()\n",
    "print('{} --> {}'.format(min(df.date), max(df.date)))\n",
    "\n",
    "ds.updateData()\n",
    "df = ds.getDataframe()\n",
    "print('{} --> {}'.format(min(df.date), max(df.date)))\n",
    "\n",
    "ds.saveDataToFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_test(djia_ds, 'AAPL', LinearStockForecaster,\n",
    "             str_to_datetime('2015-04-01'), str_to_datetime('2018-03-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = TradingDaysHelper()\n",
    "days = h.get_trading_days_in_range(TradingDaysHelper.str_to_datetime('2019-04-01'), TradingDaysHelper.str_to_datetime('2019-04-30'))\n",
    "\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "ds.loaDataFromFile('data/djia_20140303-20190315.pkl')\n",
    "trading_days_helper = TradingDaysHelper()\n",
    "\n",
    "m = LinearStockForecaster('AAPL', ds, trading_days_helper)\n",
    "m.train(str_to_datetime('2015-04-01'), str_to_datetime('2018-03-31'))\n",
    "preds = m.predict(str_to_datetime('2018-04-01'), str_to_datetime('2018-06-30'))\n",
    "\n",
    "training_set = ds.getDataframe('AAPL', str_to_datetime('2015-04-01'), str_to_datetime('2018-03-31'))\n",
    "validation_set = ds.getDataframe('AAPL', str_to_datetime('2018-04-01'), str_to_datetime('2018-06-30'))\n",
    "\n",
    "plt.plot(training_set.date, training_set.close, label='Training')\n",
    "plt.plot(validation_set.date, validation_set.close, label='Validation')\n",
    "plt.plot(preds.date, preds.predicted_price, label='Prediction')\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.loadDatasetFromFile(os.path.join('data', 'djia_20140303-20190315.pkl'))\n",
    "trading_days_helper = TradingDaysHelper()\n",
    "#print(ds.dataframe)\n",
    "\n",
    "#ts = ds.getSubset(str_to_datetime('2015-04-01'), str_to_datetime('2018-03-31'))\n",
    "#tdf = ts.getDataframe()\n",
    "#print('{} --> {}'.format(min(tdf.date), max(tdf.date)))\n",
    "\n",
    "tds = ds.getSubset(ticker_symbol=['AAPL', 'IBM', 'MSFT'], from_date=str_to_datetime('2019-03-01'), to_date=str_to_datetime('2019-03-10'))\n",
    "print(tds.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days_helper = TradingDaysHelper()\n",
    "\n",
    "ds = Dataset.loadDatasetFromFile(os.path.join('data', 'djia_20140303-20190315.pkl'))\n",
    "training_ds = ds.getSubset(ticker_symbol='AAPL',\n",
    "                           from_date=str_to_datetime('2015-04-01'),\n",
    "                           to_date=str_to_datetime('2018-03-31'))\n",
    "validation_ds = ds.getSubset(ticker_symbol='AAPL',\n",
    "                             from_date=str_to_datetime('2018-04-01'),\n",
    "                             to_date=str_to_datetime('2018-06-30'))\n",
    "\n",
    "m = LinearStockForecaster('AAPL', training_ds, trading_days_helper)\n",
    "m.train()\n",
    "preds = m.predict(str_to_datetime('2018-04-01'), str_to_datetime('2018-06-30'))\n",
    "\n",
    "plt.plot(training_ds.dataframe.date, training_ds.dataframe.close, label='Training')\n",
    "plt.plot(validation_ds.dataframe.date, validation_ds.dataframe.close, label='Validation')\n",
    "plt.plot(preds.date, preds.predicted_price, label='Prediction')\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
